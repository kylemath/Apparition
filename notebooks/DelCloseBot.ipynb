{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DelCloseBot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kylemath/DelCloseBot/blob/master/notebooks/DelCloseBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "AVOIVLl1zWY6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## DelCloseBot\n",
        "\n",
        "Goal is to make a DelCloseBot using old youtube footage. Will have live actor filmed with webcam during show whose pose gets transformed into real time DelClose Poses shown to audience, with voice impressonation reading lines scripted from dialogue AI. \n",
        "\n",
        "\n",
        "*   Using https://github.com/datitran/face2face-demo\n",
        "*   youtube video here https://www.youtube.com/watch?v=DjbQaSPPsqA\n",
        "*   saved into .mp4 with https://www.onlinevideoconverter.com/youtube-converter \n",
        "\n",
        "\n",
        "\n",
        "Instructions:\n",
        "* Connect colab to google drive \n",
        "* save the .mp4 video into a folder, \n",
        "* download the facial landmark model from http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "* after uncompressing locally and saving to google drive \n",
        "\n",
        "Tactics:\n",
        "* Convert video into side by side images of video and face structure\n",
        "* Train model on these side by side images to predict DelClose from Face pose\n",
        "* Use live webam to get net face structure\n",
        "* Convert new face structure to DelClose pose with model in real time"
      ]
    },
    {
      "metadata": {
        "id": "UfVyESCxTaiu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Instal git repo**"
      ]
    },
    {
      "metadata": {
        "id": "REuKAVgQSfq4",
        "colab_type": "code",
        "outputId": "2508e57f-38af-4e8b-eb6b-958441917bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/datitran/face2face-demo.git --recursive\n",
        "%cd face2face-demo\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'face2face-demo'...\n",
            "remote: Enumerating objects: 1, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 33 (delta 0), reused 0 (delta 0), pack-reused 32\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n",
            "/content/face2face-demo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kxb9oXX5Tcth",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Install anaconda and setup to use**"
      ]
    },
    {
      "metadata": {
        "id": "F8uDPzNttXNv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4474
        },
        "outputId": "0a21975c-766b-45af-c66c-f632303100b8"
      },
      "cell_type": "code",
      "source": [
        "!wget -c https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh\n",
        "!chmod +x Anaconda3-5.1.0-Linux-x86_64.sh\n",
        "!bash ./Anaconda3-5.1.0-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages/')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-13 19:44:22--  https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.16.19.10, 104.16.18.10, 2606:4700::6810:120a, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.16.19.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577996269 (551M) [application/x-sh]\n",
            "Saving to: ‘Anaconda3-5.1.0-Linux-x86_64.sh’\n",
            "\n",
            "Anaconda3-5.1.0-Lin 100%[===================>] 551.22M   116MB/s    in 5.1s    \n",
            "\n",
            "2019-01-13 19:44:27 (109 MB/s) - ‘Anaconda3-5.1.0-Linux-x86_64.sh’ saved [577996269/577996269]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "installing: python-3.6.4-hc3d631a_1 ...\n",
            "Python 3.6.4 :: Anaconda, Inc.\n",
            "installing: ca-certificates-2017.08.26-h1d4fec5_0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: intel-openmp-2018.0.0-hc7b2577_8 ...\n",
            "installing: libgcc-ng-7.2.0-h7cc24e2_2 ...\n",
            "installing: libgfortran-ng-7.2.0-h9f7466a_2 ...\n",
            "installing: libstdcxx-ng-7.2.0-h7a57d05_2 ...\n",
            "installing: bzip2-1.0.6-h9a117a8_4 ...\n",
            "installing: expat-2.2.5-he0dffb1_0 ...\n",
            "installing: gmp-6.1.2-h6c8ec71_1 ...\n",
            "installing: graphite2-1.3.10-hf63cedd_1 ...\n",
            "installing: icu-58.2-h9c2bf20_1 ...\n",
            "installing: jbig-2.1-hdba287a_0 ...\n",
            "installing: jpeg-9b-h024ee3a_2 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: libsodium-1.0.15-hf101ebd_0 ...\n",
            "installing: libtool-2.4.6-h544aabb_3 ...\n",
            "installing: libxcb-1.12-hcd93eb1_4 ...\n",
            "installing: lzo-2.10-h49e0be7_2 ...\n",
            "installing: mkl-2018.0.1-h19d6760_4 ...\n",
            "installing: ncurses-6.0-h9df7e31_2 ...\n",
            "installing: openssl-1.0.2n-hb7f436b_0 ...\n",
            "installing: patchelf-0.9-hf79760b_2 ...\n",
            "installing: pcre-8.41-hc27e229_1 ...\n",
            "installing: pixman-0.34.0-hceecf20_3 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: unixodbc-2.3.4-hc36303a_1 ...\n",
            "installing: xz-5.2.3-h55aa19d_2 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: glib-2.53.6-h5d9569c_2 ...\n",
            "installing: hdf5-1.10.1-h9caa474_1 ...\n",
            "installing: libedit-3.1-heed3624_0 ...\n",
            "installing: libpng-1.6.34-hb9fc6fc_0 ...\n",
            "installing: libssh2-1.8.0-h9cfc8f7_4 ...\n",
            "installing: libtiff-4.0.9-h28f6b97_0 ...\n",
            "installing: libxml2-2.9.7-h26e45fe_0 ...\n",
            "installing: mpfr-3.1.5-h11a74b3_2 ...\n",
            "installing: pandoc-1.19.2.1-hea2e7c5_1 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: zeromq-4.2.2-hbedb6e5_2 ...\n",
            "installing: dbus-1.12.2-hc3f9b76_1 ...\n",
            "installing: freetype-2.8-hab7d2ae_1 ...\n",
            "installing: gstreamer-1.12.4-hb53b477_0 ...\n",
            "installing: libcurl-7.58.0-h1ad7b7a_0 ...\n",
            "installing: libxslt-1.1.32-h1312cb7_0 ...\n",
            "installing: mpc-1.0.3-hec55b23_5 ...\n",
            "installing: sqlite-3.22.0-h1bed415_0 ...\n",
            "installing: curl-7.58.0-h84994c4_0 ...\n",
            "installing: fontconfig-2.12.4-h88586e7_1 ...\n",
            "installing: gst-plugins-base-1.12.4-h33fb286_0 ...\n",
            "installing: alabaster-0.7.10-py36h306e16b_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: attrs-17.4.0-py36_0 ...\n",
            "installing: backports-1.0-py36hfa02d7e_1 ...\n",
            "installing: beautifulsoup4-4.6.0-py36h49b8c8c_1 ...\n",
            "installing: bitarray-0.8.1-py36h14c3975_1 ...\n",
            "installing: boto-2.48.0-py36h6e4cd66_1 ...\n",
            "installing: cairo-1.14.12-h77bcde2_0 ...\n",
            "installing: certifi-2018.1.18-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: click-6.7-py36h5253387_0 ...\n",
            "installing: cloudpickle-0.5.2-py36_1 ...\n",
            "installing: colorama-0.3.9-py36h489cec4_0 ...\n",
            "installing: contextlib2-0.5.5-py36h6c84a62_0 ...\n",
            "installing: dask-core-0.16.1-py36_0 ...\n",
            "installing: decorator-4.2.1-py36_0 ...\n",
            "installing: docutils-0.14-py36hb0f60f5_0 ...\n",
            "installing: entrypoints-0.2.3-py36h1aec115_2 ...\n",
            "installing: et_xmlfile-1.0.1-py36hd6bccc3_0 ...\n",
            "installing: fastcache-1.0.2-py36h14c3975_2 ...\n",
            "installing: filelock-2.0.13-py36h646ffb5_0 ...\n",
            "installing: glob2-0.6-py36he249c77_0 ...\n",
            "installing: gmpy2-2.0.8-py36hc8893dd_2 ...\n",
            "installing: greenlet-0.4.12-py36h2d503a6_0 ...\n",
            "installing: heapdict-1.0.0-py36_2 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: imagesize-0.7.1-py36h52d8127_0 ...\n",
            "installing: ipython_genutils-0.2.0-py36hb52b0d5_0 ...\n",
            "installing: itsdangerous-0.24-py36h93cc618_1 ...\n",
            "installing: jdcal-1.3-py36h4c697fb_0 ...\n",
            "installing: lazy-object-proxy-1.3.1-py36h10fcdad_0 ...\n",
            "installing: llvmlite-0.21.0-py36ha241eea_0 ...\n",
            "installing: locket-0.2.0-py36h787c0ad_1 ...\n",
            "installing: lxml-4.1.1-py36hf71bdeb_1 ...\n",
            "installing: markupsafe-1.0-py36hd9260cd_1 ...\n",
            "installing: mccabe-0.6.1-py36h5ad9710_1 ...\n",
            "installing: mistune-0.8.3-py36_0 ...\n",
            "installing: mkl-service-1.1.2-py36h17a0993_4 ...\n",
            "installing: mpmath-1.0.0-py36hfeacd6b_2 ...\n",
            "installing: msgpack-python-0.5.1-py36h6bb024c_0 ...\n",
            "installing: multipledispatch-0.4.9-py36h41da3fb_0 ...\n",
            "installing: numpy-1.14.0-py36h3dfced4_1 ...\n",
            "installing: olefile-0.45.1-py36_0 ...\n",
            "installing: pandocfilters-1.4.2-py36ha6701b7_1 ...\n",
            "installing: parso-0.1.1-py36h35f843b_0 ...\n",
            "installing: path.py-10.5-py36h55ceabb_0 ...\n",
            "installing: pep8-1.7.1-py36_0 ...\n",
            "installing: pickleshare-0.7.4-py36h63277f8_0 ...\n",
            "installing: pkginfo-1.4.1-py36h215d178_1 ...\n",
            "installing: pluggy-0.6.0-py36hb689045_0 ...\n",
            "installing: ply-3.10-py36hed35086_0 ...\n",
            "installing: psutil-5.4.3-py36h14c3975_0 ...\n",
            "installing: ptyprocess-0.5.2-py36h69acd42_0 ...\n",
            "installing: py-1.5.2-py36h29bf505_0 ...\n",
            "installing: pycodestyle-2.3.1-py36hf609f19_0 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pycrypto-2.6.1-py36h14c3975_7 ...\n",
            "installing: pycurl-7.43.0.1-py36hb7f436b_0 ...\n",
            "installing: pyodbc-4.0.22-py36hf484d3e_0 ...\n",
            "installing: pyparsing-2.2.0-py36hee85983_1 ...\n",
            "installing: pysocks-1.6.7-py36hd97a5b1_1 ...\n",
            "installing: pytz-2017.3-py36h63b9c63_0 ...\n",
            "installing: pyyaml-3.12-py36hafb9ca4_1 ...\n",
            "installing: pyzmq-16.0.3-py36he2533c7_0 ...\n",
            "installing: qt-5.6.2-h974d657_12 ...\n",
            "installing: qtpy-1.3.1-py36h3691cc8_0 ...\n",
            "installing: rope-0.10.7-py36h147e2ec_0 ...\n",
            "installing: ruamel_yaml-0.15.35-py36h14c3975_1 ...\n",
            "installing: send2trash-1.4.2-py36_0 ...\n",
            "installing: simplegeneric-0.8.1-py36_2 ...\n",
            "installing: sip-4.18.1-py36h51ed4ed_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: snowballstemmer-1.2.1-py36h6febd40_0 ...\n",
            "installing: sortedcontainers-1.5.9-py36_0 ...\n",
            "installing: sphinxcontrib-1.0-py36h6d0f590_1 ...\n",
            "installing: sqlalchemy-1.2.1-py36h14c3975_0 ...\n",
            "installing: tblib-1.3.2-py36h34cf8b6_0 ...\n",
            "installing: testpath-0.3.1-py36h8cadb63_0 ...\n",
            "installing: toolz-0.9.0-py36_0 ...\n",
            "installing: tornado-4.5.3-py36_0 ...\n",
            "installing: typing-3.6.2-py36h7da032a_0 ...\n",
            "installing: unicodecsv-0.14.1-py36ha668878_0 ...\n",
            "installing: wcwidth-0.1.7-py36hdf4376a_0 ...\n",
            "installing: webencodings-0.5.1-py36h800622e_1 ...\n",
            "installing: werkzeug-0.14.1-py36_0 ...\n",
            "installing: wrapt-1.10.11-py36h28b7045_0 ...\n",
            "installing: xlrd-1.1.0-py36h1db9f0c_1 ...\n",
            "installing: xlsxwriter-1.0.2-py36h3de1aca_0 ...\n",
            "installing: xlwt-1.3.0-py36h7b00a1f_0 ...\n",
            "installing: babel-2.5.3-py36_0 ...\n",
            "installing: backports.shutil_get_terminal_size-1.0.0-py36hfea85ff_2 ...\n",
            "installing: bottleneck-1.2.1-py36haac1ea0_0 ...\n",
            "installing: cffi-1.11.4-py36h9745a5d_0 ...\n",
            "installing: conda-verify-2.0.0-py36h98955d8_0 ...\n",
            "installing: cycler-0.10.0-py36h93f1223_0 ...\n",
            "installing: cytoolz-0.9.0-py36h14c3975_0 ...\n",
            "installing: h5py-2.7.1-py36h3585f63_0 ...\n",
            "installing: harfbuzz-1.7.4-hc5b324e_0 ...\n",
            "installing: html5lib-1.0.1-py36h2f9c1c0_0 ...\n",
            "installing: jedi-0.11.1-py36_0 ...\n",
            "installing: networkx-2.1-py36_0 ...\n",
            "installing: nltk-3.2.5-py36h7532b22_0 ...\n",
            "installing: numba-0.36.2-np114py36hc6662d5_0 ...\n",
            "installing: numexpr-2.6.4-py36hc4a3f9a_0 ...\n",
            "installing: openpyxl-2.4.10-py36_0 ...\n",
            "installing: packaging-16.8-py36ha668100_1 ...\n",
            "installing: partd-0.3.8-py36h36fd896_0 ...\n",
            "installing: pathlib2-2.3.0-py36h49efa8e_0 ...\n",
            "installing: pexpect-4.3.1-py36_0 ...\n",
            "installing: pillow-5.0.0-py36h3deb7b8_0 ...\n",
            "installing: pyqt-5.6.0-py36h0386399_5 ...\n",
            "installing: python-dateutil-2.6.1-py36h88d3b88_1 ...\n",
            "installing: pywavelets-0.5.2-py36he602eb0_0 ...\n",
            "installing: qtawesome-0.4.4-py36h609ed8c_0 ...\n",
            "installing: scipy-1.0.0-py36hbf646e7_0 ...\n",
            "installing: setuptools-38.4.0-py36_0 ...\n",
            "installing: singledispatch-3.4.0.3-py36h7a266c3_0 ...\n",
            "installing: sortedcollections-0.5.3-py36h3c761f9_0 ...\n",
            "installing: sphinxcontrib-websupport-1.0.1-py36hb5cb234_1 ...\n",
            "installing: sympy-1.1.1-py36hc6d1c1c_0 ...\n",
            "installing: terminado-0.8.1-py36_1 ...\n",
            "installing: traitlets-4.3.2-py36h674d592_0 ...\n",
            "installing: zict-0.1.3-py36h3a3bf81_0 ...\n",
            "installing: astroid-1.6.1-py36_0 ...\n",
            "installing: bleach-2.1.2-py36_0 ...\n",
            "installing: clyent-1.2.2-py36h7e57e65_1 ...\n",
            "installing: cryptography-2.1.4-py36hd09be54_0 ...\n",
            "installing: cython-0.27.3-py36h1860423_0 ...\n",
            "installing: datashape-0.5.4-py36h3ad6b5c_0 ...\n",
            "installing: distributed-1.20.2-py36_0 ...\n",
            "installing: get_terminal_size-1.0.0-haa9412d_0 ...\n",
            "installing: gevent-1.2.2-py36h2fe25dc_0 ...\n",
            "installing: imageio-2.2.0-py36he555465_0 ...\n",
            "installing: isort-4.2.15-py36had401c0_0 ...\n",
            "installing: jinja2-2.10-py36ha16c418_0 ...\n",
            "installing: jsonschema-2.6.0-py36h006f8b5_0 ...\n",
            "installing: jupyter_core-4.4.0-py36h7c827e3_0 ...\n",
            "installing: matplotlib-2.1.2-py36h0e671d2_0 ...\n",
            "installing: navigator-updater-0.1.0-py36h14770f7_0 ...\n",
            "installing: nose-1.3.7-py36hcdf7029_2 ...\n",
            "installing: pandas-0.22.0-py36hf484d3e_0 ...\n",
            "installing: pango-1.41.0-hd475d92_0 ...\n",
            "installing: patsy-0.5.0-py36_0 ...\n",
            "installing: pyflakes-1.6.0-py36h7bd6a15_0 ...\n",
            "installing: pygments-2.2.0-py36h0d3125c_0 ...\n",
            "installing: pytables-3.4.2-py36h3b5282a_2 ...\n",
            "installing: pytest-3.3.2-py36_0 ...\n",
            "installing: scikit-learn-0.19.1-py36h7aa7ec6_0 ...\n",
            "installing: wheel-0.30.0-py36hfd4bba0_1 ...\n",
            "installing: astropy-2.0.3-py36h14c3975_0 ...\n",
            "installing: bkcharts-0.2-py36h735825a_0 ...\n",
            "installing: bokeh-0.12.13-py36h2f9c1c0_0 ...\n",
            "installing: flask-0.12.2-py36hb24657c_0 ...\n",
            "installing: jupyter_client-5.2.2-py36_0 ...\n",
            "installing: nbformat-4.4.0-py36h31c9010_0 ...\n",
            "installing: pip-9.0.1-py36h6c6f9ce_4 ...\n",
            "installing: prompt_toolkit-1.0.15-py36h17d85b1_0 ...\n",
            "installing: pylint-1.8.2-py36_0 ...\n",
            "installing: pyopenssl-17.5.0-py36h20ba746_0 ...\n",
            "installing: statsmodels-0.8.0-py36h8533d0b_0 ...\n",
            "installing: dask-0.16.1-py36_0 ...\n",
            "installing: flask-cors-3.0.3-py36h2d857d3_0 ...\n",
            "installing: ipython-6.2.1-py36h88c514a_1 ...\n",
            "installing: nbconvert-5.3.1-py36hb41ffb7_0 ...\n",
            "installing: seaborn-0.8.1-py36hfad7ec4_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: ipykernel-4.8.0-py36_0 ...\n",
            "installing: odo-0.5.1-py36h90ed295_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: scikit-image-0.13.1-py36h14c3975_1 ...\n",
            "installing: anaconda-client-1.6.9-py36_0 ...\n",
            "installing: blaze-0.11.3-py36h4e06776_0 ...\n",
            "installing: jupyter_console-5.2.0-py36he59e554_1 ...\n",
            "installing: notebook-5.4.0-py36_0 ...\n",
            "installing: qtconsole-4.3.1-py36h8f73b5b_0 ...\n",
            "installing: sphinx-1.6.6-py36_0 ...\n",
            "installing: anaconda-project-0.8.2-py36h44fb852_0 ...\n",
            "installing: jupyterlab_launcher-0.10.2-py36_0 ...\n",
            "installing: numpydoc-0.7.0-py36h18f165f_0 ...\n",
            "installing: widgetsnbextension-3.1.0-py36_0 ...\n",
            "installing: anaconda-navigator-1.7.0-py36_0 ...\n",
            "installing: ipywidgets-7.1.1-py36_0 ...\n",
            "installing: jupyterlab-0.31.5-py36_0 ...\n",
            "installing: spyder-3.2.6-py36_0 ...\n",
            "installing: _ipyw_jlab_nb_ext_conf-0.1.0-py36he11e457_0 ...\n",
            "installing: jupyter-1.0.0-py36_4 ...\n",
            "installing: anaconda-5.1.0-py36_2 ...\n",
            "installing: conda-4.4.10-py36_0 ...\n",
            "installing: conda-build-3.4.1-py36_0 ...\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Anaconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Anaconda3: /usr/local\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IRwQFi8-VBPy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Create conda environment and activate it **"
      ]
    },
    {
      "metadata": {
        "id": "uxQ_OQc5uT-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1482
        },
        "outputId": "4cb7a5ba-15aa-434a-d6e6-a710cf54e911"
      },
      "cell_type": "code",
      "source": [
        "!conda env create -f environment.yml \n",
        "!source activate face2face-demo"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.4.10\n",
            "  latest version: 4.5.12\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base conda\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "opencv3 3.1.0: 100% 1.0/1 [00:17<00:00, 17.42s/it]               \n",
            "zlib 1.2.8: 100% 1.0/1 [00:00<00:00, 12.57it/s]\n",
            "ncurses 5.9: 100% 1.0/1 [00:01<00:00,  1.41s/it]               \n",
            "dlib 19.4: 100% 1.0/1 [00:01<00:00, 20.58s/it] \n",
            "libpng 1.6.27: 100% 1.0/1 [00:00<00:00,  7.62it/s]               \n",
            "openssl 1.0.2l: 100% 1.0/1 [00:02<00:00,  2.05s/it]               \n",
            "certifi 2018.8.24: 100% 1.0/1 [00:00<00:00, 11.72it/s]\n",
            "pip 9.0.1: 100% 1.0/1 [00:00<00:00,  1.03it/s]               \n",
            "libstdcxx-ng 7.2.0: 100% 1.0/1 [00:01<00:00,  1.04s/it]              \n",
            "sqlite 3.13.0: 100% 1.0/1 [00:02<00:00,  2.03s/it]               \n",
            "python 3.5.3: 100% 1.0/1 [00:08<00:00,  8.04s/it]               \n",
            "bzip2 1.0.6: 100% 1.0/1 [00:00<00:00, 16.06it/s]\n",
            "ca-certificates 2018.11.29: 100% 1.0/1 [00:00<00:00, 11.54it/s]\n",
            "mkl 2017.0.3: 100% 1.0/1 [00:57<00:00, 57.26s/it]                \n",
            "jpeg 9b: 100% 1.0/1 [00:00<00:00,  2.31it/s]               \n",
            "blas 1.0: 100% 1.0/1 [00:00<00:00, 11.96it/s]\n",
            "wheel 0.29.0: 100% 1.0/1 [00:00<00:00, 11.06it/s]\n",
            "numpy 1.13.0: 100% 1.0/1 [00:03<00:00,  3.45s/it]               \n",
            "readline 6.2: 100% 1.0/1 [00:00<00:00,  3.36it/s]               \n",
            "tbb 2019.3: 100% 1.0/1 [00:00<00:00,  2.16it/s]     \n",
            "boost 1.59.0: 100% 1.0/1 [00:13<00:00, 13.82s/it]               \n",
            "xz 5.2.2: 100% 1.0/1 [00:00<00:00,  3.02it/s]               \n",
            "tk 8.5.18: 100% 1.0/1 [00:00<00:00,  1.10it/s]               \n",
            "setuptools 27.2.0: 100% 1.0/1 [00:00<00:00,  3.96it/s]               \n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Collecting backports.weakref==1.0rc1 (from -r /content/face2face-demo/condaenv.4ii4g5m0.requirements.txt (line 1))\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f7/ae34b6818b603e264f26fe7db2bd07850ce331ce2fde74b266d61f4a2d87/backports.weakref-1.0rc1-py3-none-any.whl\n",
            "Collecting bleach==1.5.0 (from -r /content/face2face-demo/condaenv.4ii4g5m0.requirements.txt (line 2))\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Collecting html5lib==0.9999999 (from -r /content/face2face-demo/condaenv.4ii4g5m0.requirements.txt (line 3))\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K    100% |████████████████████████████████| 890kB 590kB/s \n",
            "\u001b[?25hCollecting imutils==0.4.3 (from -r /content/face2face-demo/condaenv.4ii4g5m0.requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/cf/5f19a892b73c1992b83fbe747556984e68b2c04a3967ab52ef093d89f929/imutils-0.4.3.tar.gz\n",
            "Collecting markdown==2.6.8 (from -r /content/face2face-demo/condaenv.4ii4g5m0.requirements.txt (line 5))\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/25/3f6d2cb31ec42ca5bd3bfbea99b63892b735d76e26f20dd2dcc34ffe4f0d/Markdown-2.6.8.tar.gz (307kB)\n",
            "\u001b[K    100% |████████████████████████████████| 317kB 1.9MB/s \n",
            "\u001b[?25hCollecting protobuf==3.3.0 (from -r /content/face2face-demo/condaenv.4ii4g5m0.requirements.txt (line 6))\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/d8/3520f6708e92721377116a48581260547effa7476b20185f61369bfdc4a5/protobuf-3.3.0-cp35-cp35m-manylinux1_x86_64.whl (5.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.7MB 96kB/s \n",
            "\u001b[?25hCollecting six==1.10.0 (from -r /content/face2face-demo/condaenv.4ii4g5m0.requirements.txt (line 7))\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/0a/b6723e1bc4c516cb687841499455a8505b44607ab535be01091c0f24f079/six-1.10.0-py2.py3-none-any.whl\n",
            "Collecting tensorflow==1.2.1 (from -r /content/face2face-demo/condaenv.4ii4g5m0.requirements.txt (line 8))\n",
            "  Downloading https://files.pythonhosted.org/packages/26/fe/62ce8c45c13831582998da21590b2fc1c305fdd2f0c9d2ced110f9874256/tensorflow-1.2.1-cp35-cp35m-manylinux1_x86_64.whl (34.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 34.5MB 15kB/s \n",
            "\u001b[?25hCollecting werkzeug==0.12.2 (from -r /content/face2face-demo/condaenv.4ii4g5m0.requirements.txt (line 9))\n",
            "  Downloading https://files.pythonhosted.org/packages/97/02/306e0d57fdbf467ec1c763bc1757ec6ba20b1332e0ea7e49111533d71d1c/Werkzeug-0.12.2-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K    100% |████████████████████████████████| 317kB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/envs/face2face-demo/lib/python3.5/site-packages (from protobuf==3.3.0->-r /content/face2face-demo/condaenv.4ii4g5m0.requirements.txt (line 6))\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/envs/face2face-demo/lib/python3.5/site-packages (from tensorflow==1.2.1->-r /content/face2face-demo/condaenv.4ii4g5m0.requirements.txt (line 8))\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/envs/face2face-demo/lib/python3.5/site-packages (from tensorflow==1.2.1->-r /content/face2face-demo/condaenv.4ii4g5m0.requirements.txt (line 8))\n",
            "Building wheels for collected packages: html5lib, imutils, markdown\n",
            "  Running setup.py bdist_wheel for html5lib ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "  Running setup.py bdist_wheel for imutils ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/97/19/33/9c8b5e348f3e1d2d7f9a843ce736379a39fa6eb6c906287efe\n",
            "  Running setup.py bdist_wheel for markdown ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/8d/f6/5a/5306219d3eecbae42705af03bd4f4db7ce7bb8e39e24174e4f\n",
            "Successfully built html5lib imutils markdown\n",
            "Installing collected packages: backports.weakref, six, html5lib, bleach, imutils, markdown, protobuf, werkzeug, tensorflow\n",
            "Successfully installed backports.weakref-1.0rc1 bleach-1.5.0 html5lib-0.9999999 imutils-0.4.3 markdown-2.6.8 protobuf-3.3.0 six-1.10.0 tensorflow-1.2.1 werkzeug-0.12.2\n",
            "#\n",
            "# To activate this environment, use:\n",
            "# > source activate face2face-demo\n",
            "#\n",
            "# To deactivate an active environment, use:\n",
            "# > source deactivate\n",
            "#\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ACoWgUmtVGq9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Install some needed packages **\n",
        "\n",
        "ISSUE - dlib install takes about 10 minutes to compile, find way to speed up?"
      ]
    },
    {
      "metadata": {
        "id": "taOvzPSEANdp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "a6655a74-7fa4-4a03-cbb0-61642ea28358"
      },
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!pip install imutils==0.4.3\n",
        "!pip install tensorflow==1.2.1\n",
        "!pip install dlib\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-python\n",
            "  Downloading https://files.pythonhosted.org/packages/37/49/874d119948a5a084a7ebe98308214098ef3471d76ab74200f9800efeef15/opencv_python-4.0.0.21-cp36-cp36m-manylinux1_x86_64.whl (25.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 25.4MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/site-packages (from opencv-python)\n",
            "Installing collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.0.0.21\n",
            "Collecting imutils==0.4.3\n",
            "  Using cached https://files.pythonhosted.org/packages/a0/cf/5f19a892b73c1992b83fbe747556984e68b2c04a3967ab52ef093d89f929/imutils-0.4.3.tar.gz\n",
            "Building wheels for collected packages: imutils\n",
            "  Running setup.py bdist_wheel for imutils ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/97/19/33/9c8b5e348f3e1d2d7f9a843ce736379a39fa6eb6c906287efe\n",
            "Successfully built imutils\n",
            "Installing collected packages: imutils\n",
            "Successfully installed imutils-0.4.3\n",
            "Collecting tensorflow==1.2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/d0/96269b9ecfcc55cb38779831595e0521c34ef4ecdeba08b1ba4194cc4813/tensorflow-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (35.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 35.0MB 33kB/s \n",
            "\u001b[?25hCollecting bleach==1.5.0 (from tensorflow==1.2.1)\n",
            "  Using cached https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.2.1)\n",
            "Collecting markdown>=2.6.8 (from tensorflow==1.2.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl (89kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.2.1)\n",
            "Collecting backports.weakref==1.0rc1 (from tensorflow==1.2.1)\n",
            "  Using cached https://files.pythonhosted.org/packages/6a/f7/ae34b6818b603e264f26fe7db2bd07850ce331ce2fde74b266d61f4a2d87/backports.weakref-1.0rc1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.2.1)\n",
            "Collecting html5lib==0.9999999 (from tensorflow==1.2.1)\n",
            "  Using cached https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/site-packages (from tensorflow==1.2.1)\n",
            "Collecting protobuf>=3.2.0 (from tensorflow==1.2.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/f9/28787754923612ca9bfdffc588daa05580ed70698add063a5629d1a4209d/protobuf-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.1MB 881kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/site-packages (from protobuf>=3.2.0->tensorflow==1.2.1)\n",
            "Building wheels for collected packages: html5lib\n",
            "  Running setup.py bdist_wheel for html5lib ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built html5lib\n",
            "Installing collected packages: html5lib, bleach, markdown, backports.weakref, protobuf, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 2.1.2\n",
            "    Uninstalling bleach-2.1.2:\n",
            "      Successfully uninstalled bleach-2.1.2\n",
            "Successfully installed backports.weakref-1.0rc1 bleach-1.5.0 html5lib-0.9999999 markdown-3.0.1 protobuf-3.6.1 tensorflow-1.2.1\n",
            "Collecting dlib\n",
            "  Downloading https://files.pythonhosted.org/packages/35/8d/e4ddf60452e2fb1ce3164f774e68968b3f110f1cb4cd353235d56875799e/dlib-19.16.0.tar.gz (3.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.3MB 334kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: dlib\n",
            "  Running setup.py bdist_wheel for dlib ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ce/f9/bc/1c51cd0b40a2b5dfd46ab79a73832b41e7c3aa918a508154f0\n",
            "Successfully built dlib\n",
            "Installing collected packages: dlib\n",
            "Successfully installed dlib-19.16.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R0Yx7Ss0zZD-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Mount your google drive to load and save from**\n",
        "\n",
        "\n",
        "Note you have to follow the link here and get the activation code before proceeding"
      ]
    },
    {
      "metadata": {
        "id": "TU7xd4O0Svbu",
        "colab_type": "code",
        "outputId": "52fd52f1-0990-41f5-fb5c-5ab8f2f7e89f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "#mount google drive to load own images, follow link and get code and paste in below\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7xT6RqIhVTKe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Processes the source video to find frames with faces, and pull out the face structure, save side by side image **"
      ]
    },
    {
      "metadata": {
        "id": "zOW-THnuAOFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python generate_train_data.py \\\n",
        "  --file /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/DelCloseMono.mp4 \\\n",
        "  --num 400 \\\n",
        "  --landmark-model /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/shape_predictor_68_face_landmarks.dat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cmfA--ZmAOH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5da2d743-7b2c-4b84-b703-25d7e514fd81"
      },
      "cell_type": "code",
      "source": [
        "# Clone the repo from Christopher Hesse's pix2pix TensorFlow implementation\n",
        "%cd ..\n",
        "!git clone https://github.com/affinelayer/pix2pix-tensorflow.git\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'pix2pix-tensorflow'...\n",
            "remote: Enumerating objects: 261, done.\u001b[K\n",
            "remote: Total 261 (delta 0), reused 0 (delta 0), pack-reused 261\u001b[K\n",
            "Receiving objects: 100% (261/261), 13.33 MiB | 33.95 MiB/s, done.\n",
            "Resolving deltas: 100% (105/105), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pgFb0wi_Zkuj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9d34e2c-2905-4493-ce2e-6a8dba239159"
      },
      "cell_type": "code",
      "source": [
        "# Move the original and landmarks folder into the google drive folder\n",
        "!cp -r face2face-demo/landmarks -r face2face-demo/original /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/photos\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pix2pix-tensorflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XHuBtrI67kem",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f06d9f74-0e99-4452-ddac-2210bee58be3"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "face2face-demo\tgdrive\tpix2pix-tensorflow  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0VCrmZYj7KHV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59a478d9-71f2-4118-8f61-4726964ba14b"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Go into the pix2pix-tensorflow folder\n",
        "%cd pix2pix-tensorflow/\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pix2pix-tensorflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-L4lLwUPZwhN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Resize original images\n",
        "!python tools/process.py \\\n",
        "  --input_dir /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/photos/original \\\n",
        "  --operation resize \\\n",
        "  --output_dir /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/photos/original_resized\n",
        "  \n",
        "# Resize landmark images\n",
        "!python tools/process.py \\\n",
        "  --input_dir /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/photos/landmarks \\\n",
        "  --operation resize \\\n",
        "  --output_dir /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/photos/landmarks_resized\n",
        "  \n",
        "# Combine both resized original and landmark images\n",
        "!python tools/process.py \\\n",
        "  --input_dir /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/photos/landmarks_resized \\\n",
        "  --b_dir /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/photos/original_resized \\\n",
        "  --operation combine \\\n",
        "  --output_dir /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/photos/combined\n",
        "  \n",
        "# Split into train/val set\n",
        "!python tools/split.py \\\n",
        "  --dir /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/photos/combined"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GjNIOv1OAOKa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1261
        },
        "outputId": "9dd5dc62-5c4b-4da9-b034-284ea67302fb"
      },
      "cell_type": "code",
      "source": [
        "# Train the model on the data for the first time\n",
        "!python pix2pix.py \\\n",
        "  --mode train \\\n",
        "  --output_dir /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/face2face-model \\\n",
        "  --max_epochs 200 \\\n",
        "  --input_dir /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/photos/combined/train \\\n",
        "  --which_direction AtoB \\\n",
        "  --display_freq 50 \\\n",
        "  --save_freq 200"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aspect_ratio = 1.0\n",
            "batch_size = 1\n",
            "beta1 = 0.5\n",
            "checkpoint = None\n",
            "display_freq = 50\n",
            "flip = True\n",
            "gan_weight = 1.0\n",
            "input_dir = /content/gdrive/My Drive/DeepLearning/DelCloseBot/photos/combined/train\n",
            "l1_weight = 100.0\n",
            "lab_colorization = False\n",
            "lr = 0.0002\n",
            "max_epochs = 200\n",
            "max_steps = None\n",
            "mode = train\n",
            "ndf = 64\n",
            "ngf = 64\n",
            "output_dir = /content/gdrive/My Drive/DeepLearning/DelCloseBot/face2face-model\n",
            "output_filetype = png\n",
            "progress_freq = 50\n",
            "save_freq = 200\n",
            "scale_size = 286\n",
            "seed = 472535221\n",
            "separable_conv = False\n",
            "summary_freq = 100\n",
            "trace_freq = 0\n",
            "which_direction = AtoB\n",
            "examples count = 320\n",
            "2019-01-13 20:10:18.582127: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-13 20:10:18.582186: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-13 20:10:18.582202: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-13 20:10:18.582215: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-13 20:10:18.582228: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
            "parameter_count = 57190084\n",
            "saving display images\n",
            "progress  epoch 1  step 50  image/sec 0.2  remaining 6806m\n",
            "discrim_loss 0.38179308\n",
            "gen_loss_GAN 0.51147497\n",
            "gen_loss_L1 0.10118037\n",
            "recording summary\n",
            "saving display images\n",
            "progress  epoch 1  step 100  image/sec 0.2  remaining 6830m\n",
            "discrim_loss 0.6115202\n",
            "gen_loss_GAN 0.86295855\n",
            "gen_loss_L1 0.14574859\n",
            "saving display images\n",
            "progress  epoch 1  step 150  image/sec 0.2  remaining 6814m\n",
            "discrim_loss 0.6226497\n",
            "gen_loss_GAN 1.1939822\n",
            "gen_loss_L1 0.166318\n",
            "recording summary\n",
            "saving display images\n",
            "progress  epoch 1  step 200  image/sec 0.2  remaining 6822m\n",
            "discrim_loss 0.594992\n",
            "gen_loss_GAN 1.4609942\n",
            "gen_loss_L1 0.18369864\n",
            "saving model\n",
            "Traceback (most recent call last):\n",
            "  File \"pix2pix.py\", line 803, in <module>\n",
            "    main()\n",
            "  File \"pix2pix.py\", line 769, in main\n",
            "    results = sess.run(fetches, options=options, run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 789, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 997, in _run\n",
            "    feed_dict_string, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1132, in _do_run\n",
            "    target_list, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1139, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1121, in _run_fn\n",
            "    status, run_metadata)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UmsGdV5Fl11P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1222
        },
        "outputId": "c4fbee0b-7b27-4a1f-83c2-05a758104cdb"
      },
      "cell_type": "code",
      "source": [
        "# Train the model on the data from a checkpoint\n",
        "!python pix2pix-tensorflow/pix2pix.py \\\n",
        "  --mode train \\\n",
        "  --output_dir /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/face2face-model \\\n",
        "  --max_epochs 200 \\\n",
        "  --input_dir /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/photos/combined/train \\\n",
        "  --which_direction AtoB \\\n",
        "  --display_freq 50 \\\n",
        "  --checkpoint /content/gdrive/My\\ Drive/DeepLearning/DelCloseBot/face2face-model \\\n",
        "  --save_freq 200"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aspect_ratio = 1.0\n",
            "batch_size = 1\n",
            "beta1 = 0.5\n",
            "checkpoint = /content/gdrive/My Drive/DeepLearning/DelCloseBot/face2face-model\n",
            "display_freq = 50\n",
            "flip = True\n",
            "gan_weight = 1.0\n",
            "input_dir = /content/gdrive/My Drive/DeepLearning/DelCloseBot/photos/combined/train\n",
            "l1_weight = 100.0\n",
            "lab_colorization = False\n",
            "lr = 0.0002\n",
            "max_epochs = 200\n",
            "max_steps = None\n",
            "mode = train\n",
            "ndf = 64\n",
            "ngf = 64\n",
            "output_dir = /content/gdrive/My Drive/DeepLearning/DelCloseBot/face2face-model\n",
            "output_filetype = png\n",
            "progress_freq = 50\n",
            "save_freq = 200\n",
            "scale_size = 286\n",
            "seed = 699686393\n",
            "separable_conv = False\n",
            "summary_freq = 100\n",
            "trace_freq = 0\n",
            "which_direction = AtoB\n",
            "examples count = 320\n",
            "2019-01-14 03:18:18.719988: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-14 03:18:18.720049: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-14 03:18:18.720067: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-14 03:18:18.720119: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-14 03:18:18.720155: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
            "parameter_count = 57190084\n",
            "loading model from checkpoint\n",
            "saving display images\n",
            "progress  epoch 13  step 10  image/sec 0.2  remaining 6652m\n",
            "discrim_loss 0.8314054\n",
            "gen_loss_GAN 1.7175435\n",
            "gen_loss_L1 0.14422226\n",
            "recording summary\n",
            "saving display images\n",
            "progress  epoch 13  step 60  image/sec 0.2  remaining 6684m\n",
            "discrim_loss 0.7959122\n",
            "gen_loss_GAN 1.7385631\n",
            "gen_loss_L1 0.14079136\n",
            "saving display images\n",
            "progress  epoch 13  step 110  image/sec 0.2  remaining 6661m\n",
            "discrim_loss 0.8159445\n",
            "gen_loss_GAN 1.6695079\n",
            "gen_loss_L1 0.13561772\n",
            "recording summary\n",
            "saving display images\n",
            "progress  epoch 13  step 160  image/sec 0.2  remaining 6662m\n",
            "discrim_loss 0.8240975\n",
            "gen_loss_GAN 1.6374682\n",
            "gen_loss_L1 0.13657467\n",
            "saving model\n",
            "saving display images\n",
            "progress  epoch 13  step 210  image/sec 0.2  remaining 6673m\n",
            "discrim_loss 0.8378862\n",
            "gen_loss_GAN 1.6688325\n",
            "gen_loss_L1 0.14199306\n",
            "recording summary\n",
            "saving display images\n",
            "progress  epoch 13  step 260  image/sec 0.2  remaining 6667m\n",
            "discrim_loss 0.8460852\n",
            "gen_loss_GAN 1.6969657\n",
            "gen_loss_L1 0.14471893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jlaAnBnizdCK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Oc-6_ULV5pdW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7aa4fe98-eb85-4cbc-eee7-63bc59a73ea0"
      },
      "cell_type": "code",
      "source": [
        "%pwd\n",
        "!ls"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "face2face-demo\tgdrive\tpix2pix-tensorflow  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F7N_o1MejeqL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reduce the model"
      ]
    },
    {
      "metadata": {
        "id": "EkoNCb2P5cmZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "aae45a23-5cd6-4157-9e9b-559d7a95947b"
      },
      "cell_type": "code",
      "source": [
        "!python face2face-demo/reduce_model.py \\\n",
        "  --model-input gdrive/My\\ Drive/DeepLearning/DelCloseBot/face2face-model \\\n",
        "  --model-output gdrive/My\\ Drive/DeepLearning/DelCloseBot/face2face-model-reduced"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-01-14 03:17:54.288856: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-14 03:17:54.288921: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-14 03:17:54.288939: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-14 03:17:54.288963: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-14 03:17:54.288987: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
            "Model is exported to /content/gdrive/My Drive/DeepLearning/DelCloseBot/face2face-model/model-3800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r3W18P-mjyKP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Freeze the reduced model to single file"
      ]
    },
    {
      "metadata": {
        "id": "P-dQvbN8jdtI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "6bd5addb-fc45-43e2-e119-4916ea25658a"
      },
      "cell_type": "code",
      "source": [
        "!python face2face-demo/freeze_model.py --model-folder gdrive/My\\ Drive/DeepLearning/DelCloseBot/face2face-model-reduced"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-01-14 03:18:02.950428: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-14 03:18:02.950488: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-14 03:18:02.950505: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-14 03:18:02.950522: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "2019-01-14 03:18:02.950535: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
            "Converted 60 variables to const ops.\n",
            "759 ops in the final graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aqEcOXMpj91B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now run the demo - may need to download model and do offline\n",
        "\n",
        "download frozen model\n",
        "https://drive.google.com/open?id=10hIHuvVDsOVzt2YgZzXW0fsstVTeodG3\n",
        "\n",
        "open terminal\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "bvLaVCWWj8nh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## first time\n",
        "\n",
        "git clone https://github.com/kylemath/face2face-demo.git\n",
        "\n",
        "cd face2face-demo\n",
        "\n",
        "conda env create -f environment.yml\n",
        "\n",
        "source activate face2face-demo\n",
        "\n",
        "# show 0 to show the live webcam too, show 2 to show large output image only, show 1 is face tracking\n",
        "python run_webcam_only.py \\\n",
        "  --source 0 \\\n",
        "  --show 2 \\\n",
        "  --landmark-model /Users/kylemathewson/face2face-demo/shape_predictor_68_face_landmarks.dat \\\n",
        "  --tf-model /Users/kylemathewson/face2face-demo/frozen_model.pb\n",
        "\n",
        "\n",
        "## subsequent times\n",
        "\n",
        "cd face2face-demo\n",
        "source activate face2face-demo\n",
        "\n",
        "# show 0 to show the live webcam too, show 2 to show large output image only, show 1 is face tracking\n",
        "python run_webcam_only.py \\\n",
        "  --source 0 \\\n",
        "  --show 2 \\\n",
        "  --landmark-model /Users/kylemathewson/face2face-demo/shape_predictor_68_face_landmarks.dat \\\n",
        "  --tf-model /Users/kylemathewson/face2face-demo/frozen_model.pb"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}